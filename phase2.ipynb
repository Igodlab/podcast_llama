{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Phase 2: Story Structure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This phase is the most important on this project. We are making the story structure so we basically have 3 steps for this:\n",
    "\n",
    "* Start defining the ASP approach.\n",
    "* Use the Sentiment Analysis to create emotional integration\n",
    "* The system generates multiple valid outlines that satisfy our constrains, ensuring both logical coherence and emotional resonance.\n",
    "\n",
    "So in more detail what we will be doing in code is defining multiple functions, here are the key components:\n",
    "\n",
    "1. Scene structure foundation.\n",
    "2. Narrative Functions.\n",
    "3. Constrain System.\n",
    "4. Implementation features.\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the principal libraries\n",
    "import pandas as pd \n",
    "import numpy as np \n",
    "# import torch\n",
    "import os\n",
    "from groq import Groq, Client\n",
    "from dotenv import load_dotenv \n",
    "load_dotenv()\n",
    "\n",
    "import dspy\n",
    "import tqdm as notebook_tqdm\n",
    "# import typos\n",
    "from typing import Dict, Tuple, Optional, List, Set, Optional\n",
    "\n",
    "# import other libraries\n",
    "from enum import Enum \n",
    "from dataclasses import dataclass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "open_ai_api_key = os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import keys from .env\n",
    "load_dotenv()\n",
    "groq_api_key = os.getenv(\"GROQ_API_KEY\")\n",
    "client = Client(\n",
    "    api_key=groq_api_key\n",
    "    )\n",
    "llmo = dspy.LM('openai/gpt-4o-mini', api_key=open_ai_api_key)\n",
    "dspy.configure(lm=llmo)\n",
    "# Load the clean document\n",
    "# doc_path = \"cleaned_text.txt\"\n",
    "# with open(doc_path, \"r\") as f:\n",
    "#     INPUT_FILE = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_file = \"\"\"The Eagle, the Hare, and the Beetle\n",
    "A hare was being chased by an eagle, and seeing herself lost, she begged a beetle for help, pleading for its assistance.\n",
    "The beetle asked the eagle to spare his friend. But the eagle, despising the insignificance of the beetle, devoured the hare in his presence.\n",
    "From then on, seeking revenge, the beetle observed the places where the eagle laid its eggs, and rolling them, knocked them to the ground. Seeing herself driven away from wherever she went, the eagle turned to Zeus asking for a safe place to lay her eggs.\n",
    "Zeus offered to let her place them in his lap, but the beetle, seeing this escape tactic, made a small ball of dung, flew up and dropped it on Zeus's lap.\n",
    "Zeus then stood up to shake off that filth, and unknowingly threw the eggs to the ground. That is why since then, eagles do not lay eggs during the season when beetles come out to fly.\n",
    "Moral: Never despise what seems insignificant, for there is no being so weak that it cannot reach you.\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Structure Scene Fundation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ExtractRelevantInformation(dspy.Signature):\n",
    "    \"\"\"Extract the relevant information and key themes about this story\"\"\"\n",
    "    input_text: str = dspy.InputField()\n",
    "    reasoning: str = dspy.OutputField(desc=\"Step by step reasoning and extraction of key themes\")\n",
    "    moral_of_the_story: str = dspy.OutputField(desc=\"The moral lesson or teaching (Ense√±anza) of the story\")\n",
    "    key_themes: str = dspy.OutputField(desc=\"Key themes and main characters identified in the story\")\n",
    "\n",
    "class StoryCreation(dspy.Signature):\n",
    "    \"\"\"Based on the key themes and moral of the story, create an entertaining story\"\"\"\n",
    "    input_text: str = dspy.InputField()\n",
    "    themes: str = dspy.InputField()\n",
    "    moral: str = dspy.InputField()\n",
    "    story: str = dspy.OutputField(desc=\"Create an entertaining story incorporating the themes and moral\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StoryStructure(dspy.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.extract_relevant_information = dspy.ChainOfThought(ExtractRelevantInformation)\n",
    "        self.story_creation = dspy.ChainOfThought(StoryCreation)\n",
    "\n",
    "    def forward(self, input_text):\n",
    "        # First, extract themes and moral from the initial text\n",
    "        extracted_info = self.extract_relevant_information(\n",
    "            input_text=input_text\n",
    "        )\n",
    "        \n",
    "        # Then create the story using the extracted information\n",
    "        story = self.story_creation(\n",
    "            input_text=input_text,\n",
    "            themes=extracted_info.key_themes,\n",
    "            moral=extracted_info.moral_of_the_story\n",
    "        )\n",
    "        \n",
    "        return {\n",
    "            'themes': extracted_info.key_themes,\n",
    "            'moral': extracted_info.moral_of_the_story,\n",
    "            'story': story.story,\n",
    "            'reasoning': extracted_info.reasoning\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the story generator\n",
    "generator = StoryStructure()\n",
    "\n",
    "# Generate the story and return all components\n",
    "result = generator(test_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Once upon a time in a lush green valley, there lived a swift hare named Hazel. She was known for her speed and agility, but one fateful day, while frolicking in the meadow, she caught the eye of a fierce eagle named Edgar. With his sharp talons and keen eyesight, Edgar swooped down, determined to make Hazel his next meal.\\n\\nIn a panic, Hazel darted through the tall grass, her heart racing. Just as she thought she was cornered, she spotted a small beetle named Benny, who was busy rolling a tiny ball of dung. \"Please, Benny! Help me! The eagle is after me!\" she cried, her voice trembling.\\n\\nBenny looked up at the towering eagle, who was circling above with a menacing glare. \"Edgar, please spare my friend!\" he pleaded, his voice barely a whisper against the wind. But Edgar, with a disdainful chuckle, replied, \"What can a tiny beetle do? She is nothing but a meal to me!\" With that, he swooped down and snatched Hazel away, leaving Benny in shock.\\n\\nHeartbroken and furious, Benny vowed to take revenge on the eagle. He spent days observing Edgar, learning his habits and the locations of his nests. Finally, he discovered where Edgar laid his precious eggs. With determination, Benny rolled up small balls of dirt and, with all his might, knocked the eggs from their perch, sending them crashing to the ground.\\n\\nWhen Edgar returned to find his eggs destroyed, he was filled with rage and despair. He flew to Zeus, the king of the gods, seeking a safe place to lay his eggs. Zeus, amused by the eagle\\'s plight, offered his lap as a sanctuary. But Benny, who had been watching from a distance, knew this was a chance to strike again.\\n\\nWith a clever plan, Benny crafted another ball of dung and flew up high, dropping it right onto Zeus\\'s lap. The god, taken aback by the sudden mess, stood up to shake it off, inadvertently sending Edgar\\'s new eggs tumbling to the ground once more.\\n\\nFrom that day on, Edgar learned a valuable lesson. He no longer underestimated the small and seemingly insignificant creatures around him. And as for Benny, he became a legend in the valley, proving that even the weakest can have a powerful impact.\\n\\nAnd so, the moral of the story echoed through the valley: \"Never despise what seems insignificant, for there is no being so weak that it cannot reach you.\"'"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result[\"story\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_story_result(result_dict):\n",
    "    print(\"\\n\" + \"=\"*50 + \" TEMAS \" + \"=\"*50)\n",
    "    print(result_dict['themes'])\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*50 + \" MORAL \" + \"=\"*50)\n",
    "    print(result_dict['moral'])\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*50 + \" HISTORIA \" + \"=\"*50)\n",
    "    print(result_dict['story'])\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*50 + \" RAZONAMIENTO \" + \"=\"*50)\n",
    "    print(result_dict['reasoning'])\n",
    "    print(\"\\n\" + \"=\"*120)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================== TEMAS ==================================================\n",
      "Key themes include vulnerability, the quest for help, revenge, the underestimation of the weak, and the consequences of one's actions. Main characters are the hare, the eagle, and the beetle.\n",
      "\n",
      "================================================== MORAL ==================================================\n",
      "Never despise what seems insignificant, for there is no being so weak that it cannot reach you.\n",
      "\n",
      "================================================== HISTORIA ==================================================\n",
      "Once upon a time in a lush green valley, there lived a swift hare named Hazel. She was known for her speed and agility, but one fateful day, while frolicking in the meadow, she caught the eye of a fierce eagle named Edgar. With his sharp talons and keen eyesight, Edgar swooped down, determined to make Hazel his next meal.\n",
      "\n",
      "In a panic, Hazel darted through the tall grass, her heart racing. Just as she thought she was cornered, she spotted a small beetle named Benny, who was busy rolling a tiny ball of dung. \"Please, Benny! Help me! The eagle is after me!\" she cried, her voice trembling.\n",
      "\n",
      "Benny looked up at the towering eagle, who was circling above with a menacing glare. \"Edgar, please spare my friend!\" he pleaded, his voice barely a whisper against the wind. But Edgar, with a disdainful chuckle, replied, \"What can a tiny beetle do? She is nothing but a meal to me!\" With that, he swooped down and snatched Hazel away, leaving Benny in shock.\n",
      "\n",
      "Heartbroken and furious, Benny vowed to take revenge on the eagle. He spent days observing Edgar, learning his habits and the locations of his nests. Finally, he discovered where Edgar laid his precious eggs. With determination, Benny rolled up small balls of dirt and, with all his might, knocked the eggs from their perch, sending them crashing to the ground.\n",
      "\n",
      "When Edgar returned to find his eggs destroyed, he was filled with rage and despair. He flew to Zeus, the king of the gods, seeking a safe place to lay his eggs. Zeus, amused by the eagle's plight, offered his lap as a sanctuary. But Benny, who had been watching from a distance, knew this was a chance to strike again.\n",
      "\n",
      "With a clever plan, Benny crafted another ball of dung and flew up high, dropping it right onto Zeus's lap. The god, taken aback by the sudden mess, stood up to shake it off, inadvertently sending Edgar's new eggs tumbling to the ground once more.\n",
      "\n",
      "From that day on, Edgar learned a valuable lesson. He no longer underestimated the small and seemingly insignificant creatures around him. And as for Benny, he became a legend in the valley, proving that even the weakest can have a powerful impact.\n",
      "\n",
      "And so, the moral of the story echoed through the valley: \"Never despise what seems insignificant, for there is no being so weak that it cannot reach you.\"\n",
      "\n",
      "================================================== RAZONAMIENTO ==================================================\n",
      "The story begins with a hare being chased by an eagle, highlighting the theme of vulnerability and the struggle for survival. The hare seeks help from a beetle, which represents the idea of seeking assistance from unexpected sources. The beetle's attempt to save the hare is met with disdain from the eagle, who underestimates the beetle's potential for revenge. The beetle's actions demonstrate resilience and cleverness as it plots against the eagle, leading to a series of events that ultimately result in the eagle's downfall. The intervention of Zeus introduces a higher authority, emphasizing the consequences of one's actions and the interconnectedness of all beings. The beetle's final act of dropping dung on Zeus symbolizes how even the smallest creatures can have a significant impact. The story concludes with a moral lesson about the importance of respecting all beings, regardless of their perceived insignificance.\n",
      "\n",
      "========================================================================================================================\n"
     ]
    }
   ],
   "source": [
    "# Print the result\n",
    "print_story_result(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"new_story.txt\", 'w', encoding='utf-8') as f:\n",
    "        f.write(result[\"story\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer\n",
    "import soundfile as sf\n",
    "\n",
    "from parler_tts import ParlerTTSForConditionalGeneration\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mau/miniconda3/envs/conda_podcastllama_env/lib/python3.11/site-packages/torch/nn/utils/weight_norm.py:143: FutureWarning: `torch.nn.utils.weight_norm` is deprecated in favor of `torch.nn.utils.parametrizations.weight_norm`.\n",
      "  WeightNorm.apply(module, name, dim)\n",
      "Config of the text_encoder: <class 'transformers.models.t5.modeling_t5.T5EncoderModel'> is overwritten by shared text_encoder config: T5Config {\n",
      "  \"_name_or_path\": \"google/flan-t5-large\",\n",
      "  \"architectures\": [\n",
      "    \"T5ForConditionalGeneration\"\n",
      "  ],\n",
      "  \"classifier_dropout\": 0.0,\n",
      "  \"d_ff\": 2816,\n",
      "  \"d_kv\": 64,\n",
      "  \"d_model\": 1024,\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"dense_act_fn\": \"gelu_new\",\n",
      "  \"dropout_rate\": 0.1,\n",
      "  \"eos_token_id\": 1,\n",
      "  \"feed_forward_proj\": \"gated-gelu\",\n",
      "  \"initializer_factor\": 1.0,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"is_gated_act\": true,\n",
      "  \"layer_norm_epsilon\": 1e-06,\n",
      "  \"model_type\": \"t5\",\n",
      "  \"n_positions\": 512,\n",
      "  \"num_decoder_layers\": 24,\n",
      "  \"num_heads\": 16,\n",
      "  \"num_layers\": 24,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"relative_attention_max_distance\": 128,\n",
      "  \"relative_attention_num_buckets\": 32,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"transformers_version\": \"4.46.1\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 32128\n",
      "}\n",
      "\n",
      "Config of the audio_encoder: <class 'parler_tts.dac_wrapper.modeling_dac.DACModel'> is overwritten by shared audio_encoder config: DACConfig {\n",
      "  \"_name_or_path\": \"parler-tts/dac_44khZ_8kbps\",\n",
      "  \"architectures\": [\n",
      "    \"DACModel\"\n",
      "  ],\n",
      "  \"codebook_size\": 1024,\n",
      "  \"frame_rate\": 86,\n",
      "  \"latent_dim\": 1024,\n",
      "  \"model_bitrate\": 8,\n",
      "  \"model_type\": \"dac_on_the_hub\",\n",
      "  \"num_codebooks\": 9,\n",
      "  \"sampling_rate\": 44100,\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.46.1\"\n",
      "}\n",
      "\n",
      "Config of the decoder: <class 'parler_tts.modeling_parler_tts.ParlerTTSForCausalLM'> is overwritten by shared decoder config: ParlerTTSDecoderConfig {\n",
      "  \"_name_or_path\": \"/fsx/yoach/tmp/artefacts/parler-tts-mini/decoder\",\n",
      "  \"activation_dropout\": 0.0,\n",
      "  \"activation_function\": \"gelu\",\n",
      "  \"add_cross_attention\": true,\n",
      "  \"architectures\": [\n",
      "    \"ParlerTTSForCausalLM\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"bos_token_id\": 1025,\n",
      "  \"codebook_weights\": null,\n",
      "  \"cross_attention_implementation_strategy\": null,\n",
      "  \"dropout\": 0.1,\n",
      "  \"eos_token_id\": 1024,\n",
      "  \"ffn_dim\": 4096,\n",
      "  \"hidden_size\": 1024,\n",
      "  \"initializer_factor\": 0.02,\n",
      "  \"is_decoder\": true,\n",
      "  \"layerdrop\": 0.0,\n",
      "  \"max_position_embeddings\": 4096,\n",
      "  \"model_type\": \"parler_tts_decoder\",\n",
      "  \"num_attention_heads\": 16,\n",
      "  \"num_codebooks\": 9,\n",
      "  \"num_cross_attention_key_value_heads\": 16,\n",
      "  \"num_hidden_layers\": 24,\n",
      "  \"num_key_value_heads\": 16,\n",
      "  \"pad_token_id\": 1024,\n",
      "  \"rope_embeddings\": false,\n",
      "  \"rope_theta\": 10000.0,\n",
      "  \"scale_embedding\": false,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.46.1\",\n",
      "  \"use_cache\": true,\n",
      "  \"use_fused_lm_heads\": false,\n",
      "  \"vocab_size\": 1088\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "model = ParlerTTSForConditionalGeneration.from_pretrained(\"parler-tts/parler-tts-mini-v1\").to(device)\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"parler-tts/parler-tts-mini-v1\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "prompt = result[\"story\"]\n",
    "description = \"A female speaker delivers a slightly expressive and animated speech with a moderate speed and pitch. The recording is of very high quality, with the speaker's voice sounding clear and very close up.\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (655 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    }
   ],
   "source": [
    "\n",
    "input_ids = tokenizer(description, return_tensors=\"pt\").input_ids.to(device)\n",
    "prompt_input_ids = tokenizer(prompt, return_tensors=\"pt\").input_ids.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "generation = model.generate(input_ids=input_ids, prompt_input_ids=prompt_input_ids)\n",
    "audio_arr = generation.cpu().numpy().squeeze()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "sf.write(\"parler_tts_out.wav\", audio_arr, model.config.sampling_rate)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_podcastllama_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
